{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0d481f3f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Alan Raydan\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0605f9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Error Estimates for Physics Informed Neural Networks Approximating the Primitive Equations\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    &u_t + uu_z +wu_z - \\nu_h u_{xx} - \\nu_z u_{zz} + p_x = 0\\\\\n",
    "    &p_z + T = 0\\\\\n",
    "    &u_x + w_z = 0\\\\\n",
    "    &T_t + uT_x + wT_z - \\kappa_h T_{xx} - \\kappa T_{zz} = Q\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feedforward Neural Network with tanh activation functions\n",
    "Here we use a standard feedforward network with 2 hidden layers with 128 nodes per layer.\n",
    "\n",
    "Let me know if you have suggestions for other network architectures/activation functions."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Feedforward neural network architecture\n",
    "class PrimitiveNet(nn.Module):\n",
    "    def __init__(self, spacial_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.spacial_dim = spacial_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(1 + self.spacial_dim, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, self.output_dim))\n",
    "\n",
    "    def forward(self, t, *x):\n",
    "        # add assert statement to ensure appropriate dimension of x equals self.spacial_dim\n",
    "        tx = torch.cat((t, *x), dim=1)\n",
    "        return self.net(tx)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Helper functions\n",
    "Functions to generate the quadrature points for the midpoint rule and the necessary residuals for the primitive equations.\n",
    "\n",
    "These residuals are taken directly from the overleaf draft, and I try to stick to the notation used in the paper. I can change them if we decide on different residuals in the future."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def generate_quadrature_points(points_per_dimension, min, max):\n",
    "    \"\"\"\n",
    "    Generates an equal number of points in each dimension according to midpoint quadrature method\n",
    "    where the interval in each dimension is of the form [min, max].\n",
    "    \"\"\"\n",
    "    midpoint_shift = (max - min) / (2 * (points_per_dimension - 1))\n",
    "    shifted_min = min + midpoint_shift\n",
    "    shifted_max = max + midpoint_shift\n",
    "    t = torch.linspace(shifted_min, shifted_max, steps=points_per_dimension)\n",
    "    x = torch.linspace(shifted_min, shifted_max, steps=points_per_dimension)\n",
    "    z = torch.linspace(shifted_min, shifted_max, steps=points_per_dimension)\n",
    "    return t, x, z\n",
    "\n",
    "def generate_interior_residuals():\n",
    "    \"\"\"\n",
    "    Evaluates needed derivatives for each of the neural nets and returns the PDE\n",
    "    residuals for the interior of the domain.\n",
    "    \"\"\"\n",
    "    tt, xx, zz = torch.meshgrid(t, x, z, indexing=\"ij\")\n",
    "    tt = tt.reshape((-1,1)).requires_grad_()\n",
    "    xx = xx.reshape((-1,1)).requires_grad_()\n",
    "    zz = zz.reshape((-1,1)).requires_grad_()\n",
    "\n",
    "    # Forward pass\n",
    "    u = u_net(tt, xx, zz)\n",
    "    w = w_net(tt, xx, zz)\n",
    "    p = p_net(tt, xx, zz)\n",
    "    T = T_net(tt, xx, zz)\n",
    "\n",
    "    # create relevant partial derivatives\n",
    "    u_t = torch.autograd.grad(torch.sum(u), tt, create_graph=True)[0]\n",
    "    u_x = torch.autograd.grad(torch.sum(u), xx, create_graph=True)[0]\n",
    "    u_z = torch.autograd.grad(torch.sum(u), zz, create_graph=True)[0]\n",
    "    u_xx = torch.autograd.grad(torch.sum(u_x), xx, create_graph=True)[0]\n",
    "    u_zz = torch.autograd.grad(torch.sum(u_z), zz, create_graph=True)[0]\n",
    "    w_z = torch.autograd.grad(torch.sum(w), zz, create_graph=True)[0]\n",
    "    p_x = torch.autograd.grad(torch.sum(p), xx, create_graph=True)[0]\n",
    "    p_z = torch.autograd.grad(torch.sum(p), zz, create_graph=True)[0]\n",
    "    T_t = torch.autograd.grad(torch.sum(T), tt, create_graph=True)[0]\n",
    "    T_x = torch.autograd.grad(torch.sum(T), xx, create_graph=True)[0]\n",
    "    T_z = torch.autograd.grad(torch.sum(T), zz, create_graph=True)[0]\n",
    "    T_xx = torch.autograd.grad(torch.sum(T_x), xx, create_graph=True)[0]\n",
    "    T_zz = torch.autograd.grad(torch.sum(T_z), zz, create_graph=True)[0]\n",
    "\n",
    "    # Evaluate residuals\n",
    "    R_i_u = u_t + u*u_x + w*u_z - v_h*u_xx - v_z*u_zz + p_x\n",
    "    R_i_p = p_z + T\n",
    "    R_i_div = u_x + w_z\n",
    "    R_i_T = T_t + u*T_x + w*T_z - k_h*T_xx - k_z*T_zz - Q(tt, xx, zz)\n",
    "\n",
    "    return R_i_u, R_i_p, R_i_div, R_i_T\n",
    "\n",
    "def generate_boundary_residuals():\n",
    "    \"\"\"\n",
    "    Evaluates needed derivatives for each of the neural nets and returns\n",
    "    the periodic boundary condition residuals.\n",
    "    \"\"\"\n",
    "    tt, xx = torch.meshgrid(t, z, indexing=\"ij\")\n",
    "    _, zz = torch.meshgrid(t, x, indexing=\"ij\")\n",
    "    tt = tt.reshape((-1,1))\n",
    "    xx = xx.reshape((-1,1))\n",
    "    zz = zz.reshape((-1,1)).requires_grad_()\n",
    "    zero = torch.zeros_like(tt, requires_grad=True)\n",
    "    one = torch.ones_like(tt, requires_grad=True)\n",
    "\n",
    "    u_boundary_x = (u_net(tt, one, zz) - u_net(tt, zero, zz)).pow(2)\n",
    "    u_boundary_z = (u_net(tt, xx, one) - u_net(tt, xx, zero)).pow(2)\n",
    "    u_partial_z_zero = torch.autograd.grad(torch.sum(u_net(tt, xx, zero)), zero, create_graph=True)[0]\n",
    "    u_partial_z_one = torch.autograd.grad(torch.sum(u_net(tt, xx, one)), one, create_graph=True)[0]\n",
    "    uR_s_e = torch.sqrt(u_boundary_x + u_boundary_z + u_partial_z_zero.pow(2) + u_partial_z_one.pow(2))\n",
    "\n",
    "    p_boundary_x = (p_net(tt, one, zz) - p_net(tt, zero, zz)).pow(2)\n",
    "    p_boundary_z = (p_net(tt, xx, one) - p_net(tt, xx, zero)).pow(2)\n",
    "    p_partial_z_zero = torch.autograd.grad(torch.sum(p_net(tt, xx, zero)), zero, create_graph=True)[0]\n",
    "    p_partial_z_one = torch.autograd.grad(torch.sum(p_net(tt, xx, one)), one, create_graph=True)[0]\n",
    "    pR_s_e = torch.sqrt(p_boundary_x + p_boundary_z + p_partial_z_zero.pow(2) + p_partial_z_one.pow(2))\n",
    "\n",
    "    w_boundary_x = (w_net(tt, one, zz) - w_net(tt, zero, zz)).pow(2)\n",
    "    w_boundary_z = w_net(tt, xx, one).pow(2) + w_net(tt, xx, zero).pow(2)\n",
    "    wR_s_o = torch.sqrt(w_boundary_x + w_boundary_z)\n",
    "\n",
    "    T_boundary_x = (T_net(tt, one, zz) - T_net(tt, zero, zz)).pow(2)\n",
    "    T_boundary_z = T_net(tt, xx, one).pow(2) + T_net(tt, xx, zero).pow(2)\n",
    "    TR_s_o = torch.sqrt(T_boundary_x + T_boundary_z)\n",
    "\n",
    "    return uR_s_e, wR_s_o, pR_s_e, TR_s_o\n",
    "\n",
    "def generate_initial_residuals():\n",
    "    \"\"\"\n",
    "    Evaluates the neural nets at initial time and\n",
    "    returns initial value condition residuals.\n",
    "    \"\"\"\n",
    "    xx, zz = torch.meshgrid(x, z, indexing='ij')\n",
    "    xx = xx.reshape((-1,1))\n",
    "    zz = zz.reshape((-1,1))\n",
    "    zero = torch.zeros_like(xx)\n",
    "    u_init = u_net(zero, xx, zz)\n",
    "    true_u_init = -torch.sin(np.pi*xx) * torch.cos(np.pi*zz)\n",
    "    R_t_u = u_init - true_u_init\n",
    "\n",
    "    T_init = T_net(zero, xx, zz)\n",
    "    true_T_init = zero\n",
    "    R_t_T = T_init - true_T_init\n",
    "\n",
    "    return R_t_u, R_t_T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Main learning loop\n",
    "\n",
    "Here we consider Taylor-Green vortex where $\\nu_z = \\nu_h = \\kappa_z = \\kappa_h = 1$ and $Q(t, x, z) = 0$.\n",
    "\n",
    "The PINN-NSE paper uses 80,000 training epochs, but this would take a long time on my machine. I might try it out anyway but it may not be necessary. The learning rate and number of quadrature points are also taken from the PINN-NSE paper as well as the choice of the midpoint rule for the quadrature."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Problem parameters\n",
    "lr = 8e-4\n",
    "epochs = int(5e3)\n",
    "spacial_dim = 2\n",
    "domain_min = 0.0\n",
    "domain_max = 1.0\n",
    "num_quad_points = 30\n",
    "v_z = 1.0\n",
    "v_h = 1.0\n",
    "k_z = 1.0\n",
    "k_h = 1.0\n",
    "Q = lambda t, x, z: torch.tensor(0.0)\n",
    "\n",
    "# Initializations\n",
    "u_net = PrimitiveNet(spacial_dim, 1)\n",
    "w_net = PrimitiveNet(spacial_dim, 1)\n",
    "p_net = PrimitiveNet(spacial_dim, 1)\n",
    "T_net = PrimitiveNet(spacial_dim, 1)\n",
    "all_params = itertools.chain(u_net.parameters(), w_net.parameters(), p_net.parameters(), T_net.parameters())\n",
    "optimizer = Adam(all_params, lr)\n",
    "t, x, z = generate_quadrature_points(num_quad_points, domain_min, domain_max)\n",
    "errors = []\n",
    "\n",
    "# Main training loop\n",
    "for i in range(epochs):\n",
    "\n",
    "    R_i_u, R_i_p, R_i_div, R_i_T = generate_interior_residuals()\n",
    "    uR_s_e, wR_s_o, pR_s_e, TR_s_o = generate_boundary_residuals()\n",
    "    R_t_u, R_t_T = generate_initial_residuals()\n",
    "\n",
    "    E_i = torch.sum(R_i_u.pow(2) + R_i_p.pow(2) + R_i_div.pow(2) + R_i_T.pow(2)) / num_quad_points**3\n",
    "    E_s = torch.sum(uR_s_e.pow(2) + wR_s_o.pow(2) + pR_s_e.pow(2) + TR_s_o.pow(2)) / num_quad_points**2\n",
    "    E_t = torch.sum(R_t_u.pow(2) + R_t_T.pow(2)) / num_quad_points**2\n",
    "    training_error = E_i + E_s + E_t\n",
    "\n",
    "    training_error.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    errors.append(training_error.detach())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training error looks okay after only 5000 epochs but might benefit from more."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(errors)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"training error\")\n",
    "#plt.yscale(\"log\")\n",
    "plt.grid()\n",
    "\n",
    "print(f\"Training error at final epoch: {errors[-1]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Currently working on plotting the trained networks to compare with benchmark solutions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}